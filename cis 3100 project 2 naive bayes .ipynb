{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51073f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import math\n",
    "import csv\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3493d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a class that contains our filepath, reading the csv file, training and test sets, and separating our features and labels\n",
    "class DataHandler:\n",
    "    #contructor to start a filepath\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "        \n",
    "    # reading the input csv file and store the data into a list\n",
    "    def read_csv(self):\n",
    "        with open(self.filepath, 'r') as file:\n",
    "            csv_reader = csv.reader(file)\n",
    "            next(csv_reader)  # Skip the header row\n",
    "            dataset = [row for row in csv_reader]\n",
    "        return dataset\n",
    "\n",
    "    #creating the training and test sets \n",
    "    def train_test_split(self, dataset, test_size=0.2):\n",
    "        #shuffling the dataset to get random points\n",
    "        shuffle(dataset)\n",
    "        #split index to determine how big the test size would be\n",
    "        split_index = int(len(dataset) * (1 - test_size))\n",
    "        #splitting up into the training and test sets \n",
    "        return dataset[:split_index], dataset[split_index:]\n",
    "\n",
    "    #creating separate features and labels from the dataset\n",
    "    def separate_features_labels(self, dataset):\n",
    "        # converting the feature values to floats \n",
    "        features = [list(map(float, data[1:-1])) for data in dataset]  # Exclude the ID and label\n",
    "        labels = [data[-1] for data in dataset]  # The label is the last element in each row\n",
    "        return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5e4550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating our naive bayes classifier\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self):\n",
    "        #intializing  dictionaries to store the means, standard deviations,\n",
    "        # and class probabilities for each class\n",
    "        self.means = {}\n",
    "        self.stds = {}\n",
    "        self.class_probabilities = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        #training the classifier by calculating the class probabilities\n",
    "        # and the means and standard deviations for each feature\n",
    "        self._calculate_class_probabilities(y)\n",
    "        self._calculate_means_stds(X, y)\n",
    "\n",
    "    def _calculate_class_probabilities(self, y):\n",
    "        #calculating the probability of each class based on label frequency\n",
    "        class_counts = {label: y.count(label) for label in set(y)}\n",
    "        total_count = len(y)\n",
    "        self.class_probabilities = {label: count / total_count for label, count in class_counts.items()}\n",
    "\n",
    "    def _calculate_means_stds(self, X, y):\n",
    "        #calculating the mean and standard deviation for each class and each feature\n",
    "        for label in self.class_probabilities:\n",
    "            # Extract features for instances of the current class\n",
    "            label_features = [X[i] for i in range(len(X)) if y[i] == label]\n",
    "            # Calculate mean and standard deviation for each feature\n",
    "            self.means[label] = [sum(f) / len(f) for f in zip(*label_features)]\n",
    "            self.stds[label] = [math.sqrt(sum([(x - mean)**2 for x in f]) / len(f)) for mean, f in zip(self.means[label], zip(*label_features))]\n",
    "\n",
    "    def predict_single(self, input_features):\n",
    "        # predicting the class of a single feature set\n",
    "        probabilities = {}\n",
    "        for label, _ in self.means.items():\n",
    "            # Start with the prior probability of the class\n",
    "            probabilities[label] = self.class_probabilities[label]\n",
    "            # Multiply by the probability of each feature\n",
    "            for i, feature in enumerate(input_features):\n",
    "                probabilities[label] *= self._calculate_probability(feature, self.means[label][i], self.stds[label][i])\n",
    "        # Return the class with the highest probability\n",
    "        return max(probabilities, key=probabilities.get)\n",
    "\n",
    "    def _calculate_probability(self, x, mean, std):\n",
    "        #calculating the probability of a feature value with a Gaussian distribution\n",
    "        exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(std,2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * std)) * exponent\n",
    "\n",
    "    def predict(self, X):\n",
    "        #predicting a list of feature sets\n",
    "        return [self.predict_single(features) for features in X]\n",
    "\n",
    "    def classification_report(self, y_true, y_pred):\n",
    "        #generating a classification report for the predictions\n",
    "        unique_labels = set(y_true)\n",
    "        report = {}\n",
    "        for label in unique_labels:\n",
    "            tp = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] == label)\n",
    "            fp = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] == label)\n",
    "            fn = sum(1 for i in range(len(y_true)) if y_true[i] == label and y_pred[i] != label)\n",
    "            tn = sum(1 for i in range(len(y_true)) if y_true[i] != label and y_pred[i] != label)\n",
    "\n",
    "            # Calculate precision, recall, and F1-score for each class\n",
    "            precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "            recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "            f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "            accuracy = (tp + tn) / len(y_true)\n",
    "\n",
    "            #printing/assigning the results\n",
    "            report[label] = {\n",
    "                'Precision': precision,\n",
    "                'Recall': recall,\n",
    "                'F1-score': f1,\n",
    "                'Accuracy': accuracy\n",
    "            }\n",
    "\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "edfd8de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "Class 4:\n",
      "  Precision: 0.90\n",
      "  Recall: 0.98\n",
      "  F1-score: 0.94\n",
      "  Accuracy: 0.95\n",
      "\n",
      "Class 2:\n",
      "  Precision: 0.99\n",
      "  Recall: 0.93\n",
      "  F1-score: 0.96\n",
      "  Accuracy: 0.95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Define the path to the CSV file containing the Iris dataset\n",
    "    filepath = '/Users/cindyhernandez/Downloads/breast_cancerno2.csv'\n",
    "\n",
    "    # Initialize the data handler with the filepath\n",
    "    # This object will handle all data operations\n",
    "    data_handler = DataHandler(filepath)\n",
    "\n",
    "    # Read the dataset from the CSV file using the read_csv method\n",
    "    # The dataset is returned as a list of lists, where each sublist is a row from the file\n",
    "    dataset = data_handler.read_csv()\n",
    "\n",
    "    # Split the dataset into training and testing parts using the train_test_split method\n",
    "    # Default split is 80% training and 20% testing\n",
    "    train_set, test_set = data_handler.train_test_split(dataset)\n",
    "\n",
    "    # Separate features and labels for the training set\n",
    "    # train_features will contain the data attributes, and train_labels will contain the target labels\n",
    "    train_features, train_labels = data_handler.separate_features_labels(train_set)\n",
    "\n",
    "    # Separate features and labels for the testing set\n",
    "    # This setup mirrors the training separation\n",
    "    test_features, test_labels = data_handler.separate_features_labels(test_set)\n",
    "\n",
    "    # Initialize the Naive Bayes Classifier\n",
    "    # This object will perform all classification tasks\n",
    "    classifier = NaiveBayesClassifier()\n",
    "\n",
    "    # Fit the classifier on the training data\n",
    "    # This process involves calculating necessary statistical parameters for the Naive Bayes algorithm\n",
    "    classifier.fit(train_features, train_labels)\n",
    "\n",
    "    # Predict the class labels for the test set features\n",
    "    # The predict method uses the trained model to estimate the labels of unseen data\n",
    "    predictions = classifier.predict(test_features)\n",
    "\n",
    "    # Generate a classification report comparing the true labels and predicted labels\n",
    "    # This report includes precision, recall, F1-score, and accuracy for each class\n",
    "    report = classifier.classification_report(test_labels, predictions)\n",
    "\n",
    "    # Print out the classification report for each class\n",
    "    print(\"Classification Report:\")\n",
    "    for label, metrics in report.items():\n",
    "        print(f\"Class {label}:\")\n",
    "        for metric, value in metrics.items():\n",
    "            print(f\"  {metric}: {value:.2f}\")\n",
    "        print()\n",
    "\n",
    "# This block checks if this script is the main program and runs the main function\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "#class 2 refers to if it is malignant tumor\n",
    "#class 4 refers to if it is benign tumor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab807867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f0116a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
